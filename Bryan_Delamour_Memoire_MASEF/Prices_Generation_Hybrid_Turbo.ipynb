{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dau.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MASEF, University Paris-Dauphine 2021:   Bryan Delamour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbo Charging Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ref: Turbocharging Monte Carlo pricing for the rough Bergomi model\n",
    "Ryan McCrickerd, Mikko S. Pakkanen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cmath import * \n",
    "import pickle\n",
    "from time import time \n",
    "import scipy.stats as sps\n",
    "from ipynb.fs.full.HybridScheme import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{array}{l}\n",
    "\\text { Training set of size } 34.000 \\text { and testing set of size } 6.000\\\\\n",
    "\\text { Rough Bergomi sample: }\\left(\\xi_{0}, \\nu, \\rho, H\\right) \\in \\mathcal{U}[0.01,0.16] \\times \\mathcal{U}[0.5,4.0] \\times \\mathcal{U}[-0.95,-0.1] \\times \\mathcal{U}[0.025,0.5]\\\\\n",
    "\\text { Strikes: }\\{0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5\\}\\\\\n",
    "\\text { Maturities: }\\{0.1,0.3,0.6,0.9,1.2,1.5,1.8,2.0\\}\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strikes = np.arange(0.5,1.6,0.1)\n",
    "maturities = np.array([0.1,0.3,0.6,0.9,1.2,1.5,1.8,2])\n",
    "S0=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading parameters \n",
    "\n",
    "model_parameters_training_File = \"model_parameters_training_data.pkl\"\n",
    "\n",
    "with open(model_parameters_training_File, 'rb') as file:  \n",
    "    model_parameters = pickle.load(file)\n",
    "\n",
    "XI = model_parameters[:,0]\n",
    "NU = model_parameters[:,1]\n",
    "RHO = model_parameters[:,2]\n",
    "H = model_parameters[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option price estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the orthogonal separation of the rBergomi price process $S_{t}$ into $S_{t}^{1}$ and $S_{t}^{2}$, where\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S_{t}^{1}:=\\mathcal{E}\\left(\\rho \\int_{0}^{1} \\sqrt{V_{u}} \\mathrm{~d} W_{u}^{1}\\right)_{t}, \\quad S_{t}^{2}:=\\mathcal{E}\\left(\\sqrt{1-\\rho^{2}} \\int_{0}^{1} \\sqrt{V_{u}} \\mathrm{~d} W_{u}^{2}\\right)_{t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control variate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This separation facilitates our Mixed estimator, which we define using\n",
    "$$\n",
    "X=B S\\left(\\left(1-\\rho^{2}\\right) \\int_{0}^{t} V_{u} \\mathrm{~d} u ; S_{t}^{1}, k\\right), \\quad Y=B S\\left(\\rho^{2}\\left(\\hat{Q}_{n}-\\int_{0}^{t} V_{u} \\mathrm{~d} u\\right) ; S_{t}^{1}, k\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to consider price estimators $\\hat{P}_{n}(k, t)$ of the following form under the rBergomi model\n",
    "$$\n",
    "\\hat{P}_{n}(k, t):=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}+\\hat{\\alpha}_{n} Y_{i}\\right)-\\hat{\\alpha}_{n} \\mathbb{E}[Y], \\quad \\hat{\\sigma}_{B S}^{n}(k, t)^{2} t=B S^{-1}\\left(\\hat{P}_{n}(k, t) ; 1, k\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute $\\hat{\\alpha}_{n}$ and $\\hat{Q}_{n}$ post-simulation from sampled $X_{i}, Y_{i}$ and $\\left(\\int_{0}^{t} V_{u} \\mathrm{~d} u\\right)$, using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\hat{\\alpha}_{n}:=-\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}_{n}\\right)\\left(Y_{i}-\\bar{Y}_{n}\\right)}{\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}_{n}\\right)^{2}}, \\quad \\hat{Q}_{n}:=\\sup \\left\\{\\left(\\int_{0}^{t} V_{u} \\mathrm{~d} u\\right)_{i}: i=1, \\ldots, n\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antithetic sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw a path of $W^{1}$ over the interval $[0, t]$, and appeal to the symmetry in distribution of $S_{t}^{1, \\pm}$, defined by\n",
    "\n",
    "\\begin{aligned}\n",
    "S_{t}^{1, \\pm} &=\\mathcal{E}\\left\\{\\pm \\rho \\int_{0}^{t} \\sqrt{V_{u}^{\\pm}} \\mathrm{d} W_{u}^{1}\\right\\}, \\quad V_{t}^{\\pm}=\\xi_{0}(t) \\exp \\left(-\\frac{\\eta^{2}}{2} t^{2 \\alpha+1}\\right)\\left(V_{t}^{\\circ}\\right)^{\\pm 1} \\\\\n",
    "V_{t}^{\\circ} &=\\exp \\left(\\eta W_{t}^{\\alpha}\\right)\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_price(S,K,V):\n",
    "    d1 = ( np.log(S)-np.log(K) + 0.5*V )*(1/np.sqrt(V))\n",
    "    d2 = d1 - np.sqrt(V)\n",
    "    p = S*sps.norm.cdf(d1) - K*sps.norm.cdf(d2)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sample of rough Bergomi parameters (40 000) , each strike and maturity in the grid (11x8), we will generate a mixed estimator of the call price using $M = 60 000$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1=time()\n",
    "\n",
    "nb_samples = 4*10**4\n",
    "N_disc = 100\n",
    "T_ind = N_disc*maturities\n",
    "T_ind=T_ind.astype(int)\n",
    "M = 6*10**4\n",
    "\n",
    "BS_prices = np.zeros( ( nb_samples, len(strikes), len(maturities) ) )\n",
    "\n",
    "\n",
    "for i in range(nb_samples):\n",
    "    m = M//2\n",
    "    rB = rBergomi_h(paths = m , N = N_disc, T = 2, H = H[i])\n",
    "    \n",
    "    #Anthitetic sampling \n",
    "    dW_ = rB.dW()\n",
    "    dW = np.r_[dW_, -dW_]\n",
    "    \n",
    "    W_h = rB.W_h(dW)\n",
    "    V = rB.V(XI[i], NU[i], W_h)\n",
    "    S1 = rB.S1(S0, RHO[i], dW, V)\n",
    "\n",
    "    QV = np.cumsum(V, axis = 1)* (1/N_disc)\n",
    "    QVT = QV[:, T_ind]\n",
    "\n",
    "    Q = np.max(QVT, axis=0) + 1e-9\n",
    "\n",
    "    ST = S1[:, T_ind]\n",
    "    VT = V[:, T_ind]\n",
    "\n",
    "    S1T = S1[:,T_ind]\n",
    "\n",
    "\n",
    "    mat = np.zeros( ( len(strikes), M , len(maturities ) ) )\n",
    "    c = np.zeros(len(maturities))\n",
    "    for k in range(len(strikes)): #Mixed Estimator \n",
    "        X = BS_price(S1T, strikes[k], (1 - RHO[i]**2) * QVT)\n",
    "        Y = BS_price(S1T, strikes[k], RHO[i]**2 * (Q - QVT))\n",
    "        eY = BS_price(1., strikes[k], RHO[i]**2 * Q)\n",
    "\n",
    "        # Asymptotically optimal weights\n",
    "        for t in range(len(maturities)):      \n",
    "            cov_mat = np.cov(X[:,t], Y[:,t])\n",
    "            c[t] = - cov_mat[0,1] / cov_mat[1,1]\n",
    "\n",
    "        mat[k,:,:] = X + c * (Y - eY) # Control variate\n",
    "    \n",
    "    P = (mat[:, :m, :] + mat[:, m:, :])*0.5\n",
    "    BS_prices[i,:,:] = np.mean(P,axis=1)\n",
    "\n",
    "    if (i%10==0):\n",
    "        print(i)\n",
    "        \n",
    "    if (i%1000 == 0):\n",
    "        BS_prices_training_File = \"BS_prices_training_data.pkl\"  \n",
    "\n",
    "        with open(BS_prices_training_File, 'wb') as file:  \n",
    "            pickle.dump(BS_prices, file)\n",
    "        \n",
    "       \n",
    "t2=time()\n",
    "print(\"Time (h)\", (t2-t1)/3600)\n",
    "    \n",
    "# 119h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Black Scholes prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving prices \n",
    "\n",
    "BS_prices_training_File = \"BS_prices_training_data.pkl\"  \n",
    "\n",
    "with open(BS_prices_training_File, 'wb') as file:\n",
    "    pickle.dump(BS_prices, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
